# backdoor-learning
Backdoor Learning about some well known or new backdoor attacks and defenses.

(experiments under Pytorch)

1.Train some benign and backdoored models based on datasets like MNIST, GTSRB, CIFAR10 and so on. Attacks include BadNet, Blend, Label Consistent and so on.

2.Analyse the activations of different layers to find similar neuron mode or path to trigger a specific backdoor attack. (to be confirmed under different attacks...)

3.If a similar mode has been found, consider how to use it to detect a backdoored model.
